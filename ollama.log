Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.
Your new public key is: 

ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOvbHZd48FNrSCN0cIFsZAd7wrYYuje2ZCjQ5i73fNEN

time=2025-08-20T10:28:47.275Z level=INFO source=routes.go:1318 msg="server config" env="map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/root/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NEW_ESTIMATES:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-08-20T10:28:47.275Z level=INFO source=images.go:477 msg="total blobs: 0"
time=2025-08-20T10:28:47.276Z level=INFO source=images.go:484 msg="total unused blobs removed: 0"
time=2025-08-20T10:28:47.276Z level=INFO source=routes.go:1371 msg="Listening on 127.0.0.1:11434 (version 0.11.5)"
time=2025-08-20T10:28:47.276Z level=INFO source=gpu.go:217 msg="looking for compatible GPUs"
time=2025-08-20T10:28:48.120Z level=INFO source=types.go:130 msg="inference compute" id=GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef library=cuda variant=v12 compute=8.6 driver=12.4 name="NVIDIA A40" total="44.3 GiB" available="44.1 GiB"
time=2025-08-20T10:28:48.121Z level=INFO source=types.go:130 msg="inference compute" id=GPU-5099149b-3124-0eff-3dd9-68d769ce801f library=cuda variant=v12 compute=8.6 driver=12.4 name="NVIDIA A40" total="44.3 GiB" available="44.1 GiB"
[GIN] 2025/08/20 - 10:29:47 | 200 |      48.753µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/20 - 10:29:47 | 404 |     614.364µs |       127.0.0.1 | POST     "/api/show"
time=2025-08-20T10:29:47.950Z level=INFO source=download.go:177 msg="downloading 90a618fe6ff2 in 66 1 GB part(s)"
time=2025-08-20T10:31:49.342Z level=INFO source=download.go:177 msg="downloading fa6710a93d78 in 1 7.2 KB part(s)"
time=2025-08-20T10:31:50.713Z level=INFO source=download.go:177 msg="downloading f60356777647 in 1 11 KB part(s)"
time=2025-08-20T10:31:52.070Z level=INFO source=download.go:177 msg="downloading d8ba2f9a17b3 in 1 18 B part(s)"
time=2025-08-20T10:31:53.416Z level=INFO source=download.go:177 msg="downloading e7233df9dcc9 in 1 490 B part(s)"
[GIN] 2025/08/20 - 10:32:53 | 200 |          3m6s |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/08/20 - 10:32:54 | 200 |  260.111933ms |       127.0.0.1 | POST     "/api/show"
time=2025-08-20T10:32:55.813Z level=INFO source=server.go:383 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /root/.ollama/models/blobs/sha256-90a618fe6ff21b09ca968df959104eb650658b0bef0faef785c18c2795d993e3 --port 41237"
time=2025-08-20T10:32:55.834Z level=INFO source=runner.go:1006 msg="starting ollama engine"
time=2025-08-20T10:32:55.835Z level=INFO source=runner.go:1043 msg="Server listening on 127.0.0.1:41237"
time=2025-08-20T10:32:56.233Z level=INFO source=server.go:488 msg="system memory" total="503.5 GiB" free="417.3 GiB" free_swap="0 B"
time=2025-08-20T10:32:56.234Z level=INFO source=memory.go:36 msg="new model will fit in available VRAM across minimum required GPUs, loading" model=/root/.ollama/models/blobs/sha256-90a618fe6ff21b09ca968df959104eb650658b0bef0faef785c18c2795d993e3 library=cuda parallel=1 required="67.3 GiB" gpus=2
time=2025-08-20T10:32:56.235Z level=INFO source=server.go:531 msg=offload library=cuda layers.requested=-1 layers.model=37 layers.offload=37 layers.split="[19 18]" memory.available="[44.1 GiB 44.1 GiB]" memory.gpu_overhead="0 B" memory.required.full="67.3 GiB" memory.required.partial="67.3 GiB" memory.required.kv="450.0 MiB" memory.required.allocations="[34.1 GiB 33.2 GiB]" memory.weights.total="59.7 GiB" memory.weights.repeating="58.6 GiB" memory.weights.nonrepeating="1.1 GiB" memory.graph.full="1.5 GiB" memory.graph.partial="1.5 GiB"
time=2025-08-20T10:32:56.237Z level=INFO source=runner.go:925 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:false KvSize:8192 KvCacheType: NumThreads:48 GPULayers:37[ID:GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef Layers:19(0..18) ID:GPU-5099149b-3124-0eff-3dd9-68d769ce801f Layers:18(19..36)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-08-20T10:32:56.331Z level=INFO source=ggml.go:130 msg="" architecture=gptoss file_type=MXFP4 name="" description="" num_tensors=471 num_key_values=30
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 2 CUDA devices:
  Device 0: NVIDIA A40, compute capability 8.6, VMM: yes, ID: GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef
  Device 1: NVIDIA A40, compute capability 8.6, VMM: yes, ID: GPU-5099149b-3124-0eff-3dd9-68d769ce801f
load_backend: loaded CUDA backend from /usr/local/lib/ollama/libggml-cuda.so
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
time=2025-08-20T10:32:56.561Z level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 CUDA.1.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.1.USE_GRAPHS=1 CUDA.1.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-08-20T10:32:56.718Z level=INFO source=ggml.go:486 msg="offloading 36 repeating layers to GPU"
time=2025-08-20T10:32:56.718Z level=INFO source=ggml.go:492 msg="offloading output layer to GPU"
time=2025-08-20T10:32:56.718Z level=INFO source=ggml.go:497 msg="offloaded 37/37 layers to GPU"
time=2025-08-20T10:32:56.719Z level=INFO source=backend.go:310 msg="model weights" device=CUDA0 size="31.0 GiB"
time=2025-08-20T10:32:56.719Z level=INFO source=backend.go:310 msg="model weights" device=CUDA1 size="28.8 GiB"
time=2025-08-20T10:32:56.719Z level=INFO source=backend.go:315 msg="model weights" device=CPU size="1.1 GiB"
time=2025-08-20T10:32:56.720Z level=INFO source=backend.go:321 msg="kv cache" device=CUDA0 size="234.0 MiB"
time=2025-08-20T10:32:56.720Z level=INFO source=backend.go:321 msg="kv cache" device=CUDA1 size="216.0 MiB"
time=2025-08-20T10:32:56.720Z level=INFO source=backend.go:332 msg="compute graph" device=CUDA0 size="1.1 GiB"
time=2025-08-20T10:32:56.720Z level=INFO source=backend.go:332 msg="compute graph" device=CUDA1 size="1.1 GiB"
time=2025-08-20T10:32:56.720Z level=INFO source=backend.go:337 msg="compute graph" device=CPU size="5.6 MiB"
time=2025-08-20T10:32:56.720Z level=INFO source=backend.go:342 msg="total memory" size="63.4 GiB"
time=2025-08-20T10:32:56.720Z level=INFO source=sched.go:473 msg="loaded runners" count=1
time=2025-08-20T10:32:56.720Z level=INFO source=server.go:1234 msg="waiting for llama runner to start responding"
time=2025-08-20T10:32:56.721Z level=INFO source=server.go:1268 msg="waiting for server to become available" status="llm server loading model"
time=2025-08-20T10:33:26.581Z level=INFO source=server.go:1272 msg="llama runner started in 30.77 seconds"
[GIN] 2025/08/20 - 10:33:26 | 200 | 32.408283291s |       127.0.0.1 | POST     "/api/generate"
time=2025-08-20T10:48:29.832Z level=INFO source=server.go:383 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /root/.ollama/models/blobs/sha256-90a618fe6ff21b09ca968df959104eb650658b0bef0faef785c18c2795d993e3 --port 40237"
time=2025-08-20T10:48:29.858Z level=INFO source=runner.go:1006 msg="starting ollama engine"
time=2025-08-20T10:48:29.858Z level=INFO source=runner.go:1043 msg="Server listening on 127.0.0.1:40237"
time=2025-08-20T10:48:30.330Z level=INFO source=server.go:488 msg="system memory" total="503.5 GiB" free="417.3 GiB" free_swap="0 B"
time=2025-08-20T10:48:30.332Z level=INFO source=memory.go:36 msg="new model will fit in available VRAM across minimum required GPUs, loading" model=/root/.ollama/models/blobs/sha256-90a618fe6ff21b09ca968df959104eb650658b0bef0faef785c18c2795d993e3 library=cuda parallel=1 required="67.3 GiB" gpus=2
time=2025-08-20T10:48:30.333Z level=INFO source=server.go:531 msg=offload library=cuda layers.requested=-1 layers.model=37 layers.offload=37 layers.split="[19 18]" memory.available="[44.1 GiB 44.1 GiB]" memory.gpu_overhead="0 B" memory.required.full="67.3 GiB" memory.required.partial="67.3 GiB" memory.required.kv="450.0 MiB" memory.required.allocations="[34.1 GiB 33.2 GiB]" memory.weights.total="59.7 GiB" memory.weights.repeating="58.6 GiB" memory.weights.nonrepeating="1.1 GiB" memory.graph.full="1.5 GiB" memory.graph.partial="1.5 GiB"
time=2025-08-20T10:48:30.335Z level=INFO source=runner.go:925 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:false KvSize:8192 KvCacheType: NumThreads:48 GPULayers:37[ID:GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef Layers:19(0..18) ID:GPU-5099149b-3124-0eff-3dd9-68d769ce801f Layers:18(19..36)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-08-20T10:48:30.444Z level=INFO source=ggml.go:130 msg="" architecture=gptoss file_type=MXFP4 name="" description="" num_tensors=471 num_key_values=30
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 2 CUDA devices:
  Device 0: NVIDIA A40, compute capability 8.6, VMM: yes, ID: GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef
  Device 1: NVIDIA A40, compute capability 8.6, VMM: yes, ID: GPU-5099149b-3124-0eff-3dd9-68d769ce801f
load_backend: loaded CUDA backend from /usr/local/lib/ollama/libggml-cuda.so
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
time=2025-08-20T10:48:30.847Z level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 CUDA.1.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.1.USE_GRAPHS=1 CUDA.1.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-08-20T10:48:31.038Z level=INFO source=ggml.go:486 msg="offloading 36 repeating layers to GPU"
time=2025-08-20T10:48:31.038Z level=INFO source=ggml.go:492 msg="offloading output layer to GPU"
time=2025-08-20T10:48:31.038Z level=INFO source=ggml.go:497 msg="offloaded 37/37 layers to GPU"
time=2025-08-20T10:48:31.040Z level=INFO source=backend.go:310 msg="model weights" device=CUDA0 size="31.0 GiB"
time=2025-08-20T10:48:31.040Z level=INFO source=backend.go:310 msg="model weights" device=CUDA1 size="28.8 GiB"
time=2025-08-20T10:48:31.041Z level=INFO source=backend.go:315 msg="model weights" device=CPU size="1.1 GiB"
time=2025-08-20T10:48:31.041Z level=INFO source=backend.go:321 msg="kv cache" device=CUDA0 size="234.0 MiB"
time=2025-08-20T10:48:31.042Z level=INFO source=backend.go:321 msg="kv cache" device=CUDA1 size="216.0 MiB"
time=2025-08-20T10:48:31.042Z level=INFO source=backend.go:332 msg="compute graph" device=CUDA0 size="1.1 GiB"
time=2025-08-20T10:48:31.043Z level=INFO source=backend.go:332 msg="compute graph" device=CUDA1 size="1.1 GiB"
time=2025-08-20T10:48:31.043Z level=INFO source=backend.go:337 msg="compute graph" device=CPU size="5.6 MiB"
time=2025-08-20T10:48:31.044Z level=INFO source=backend.go:342 msg="total memory" size="63.4 GiB"
time=2025-08-20T10:48:31.044Z level=INFO source=sched.go:473 msg="loaded runners" count=1
time=2025-08-20T10:48:31.045Z level=INFO source=server.go:1234 msg="waiting for llama runner to start responding"
time=2025-08-20T10:48:31.046Z level=INFO source=server.go:1268 msg="waiting for server to become available" status="llm server loading model"
time=2025-08-20T10:49:09.801Z level=INFO source=server.go:1272 msg="llama runner started in 39.97 seconds"
[GIN] 2025/08/20 - 10:49:54 | 200 |         1m26s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 10:53:51 | 200 | 38.772216991s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 10:55:21 | 200 | 36.978469876s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 10:56:36 | 200 | 40.807765306s |       127.0.0.1 | POST     "/api/generate"
time=2025-08-20T11:03:43.665Z level=INFO source=server.go:383 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /root/.ollama/models/blobs/sha256-90a618fe6ff21b09ca968df959104eb650658b0bef0faef785c18c2795d993e3 --port 41791"
time=2025-08-20T11:03:43.685Z level=INFO source=runner.go:1006 msg="starting ollama engine"
time=2025-08-20T11:03:43.686Z level=INFO source=runner.go:1043 msg="Server listening on 127.0.0.1:41791"
time=2025-08-20T11:03:44.088Z level=INFO source=server.go:488 msg="system memory" total="503.5 GiB" free="416.7 GiB" free_swap="0 B"
time=2025-08-20T11:03:44.089Z level=INFO source=memory.go:36 msg="new model will fit in available VRAM across minimum required GPUs, loading" model=/root/.ollama/models/blobs/sha256-90a618fe6ff21b09ca968df959104eb650658b0bef0faef785c18c2795d993e3 library=cuda parallel=1 required="67.3 GiB" gpus=2
time=2025-08-20T11:03:44.090Z level=INFO source=server.go:531 msg=offload library=cuda layers.requested=-1 layers.model=37 layers.offload=37 layers.split="[19 18]" memory.available="[44.1 GiB 44.1 GiB]" memory.gpu_overhead="0 B" memory.required.full="67.3 GiB" memory.required.partial="67.3 GiB" memory.required.kv="450.0 MiB" memory.required.allocations="[34.1 GiB 33.2 GiB]" memory.weights.total="59.7 GiB" memory.weights.repeating="58.6 GiB" memory.weights.nonrepeating="1.1 GiB" memory.graph.full="1.5 GiB" memory.graph.partial="1.5 GiB"
time=2025-08-20T11:03:44.091Z level=INFO source=runner.go:925 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:false KvSize:8192 KvCacheType: NumThreads:48 GPULayers:37[ID:GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef Layers:19(0..18) ID:GPU-5099149b-3124-0eff-3dd9-68d769ce801f Layers:18(19..36)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-08-20T11:03:44.208Z level=INFO source=ggml.go:130 msg="" architecture=gptoss file_type=MXFP4 name="" description="" num_tensors=471 num_key_values=30
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 2 CUDA devices:
  Device 0: NVIDIA A40, compute capability 8.6, VMM: yes, ID: GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef
  Device 1: NVIDIA A40, compute capability 8.6, VMM: yes, ID: GPU-5099149b-3124-0eff-3dd9-68d769ce801f
load_backend: loaded CUDA backend from /usr/local/lib/ollama/libggml-cuda.so
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
time=2025-08-20T11:03:44.466Z level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 CUDA.1.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.1.USE_GRAPHS=1 CUDA.1.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-08-20T11:03:44.923Z level=INFO source=ggml.go:486 msg="offloading 36 repeating layers to GPU"
time=2025-08-20T11:03:44.923Z level=INFO source=ggml.go:492 msg="offloading output layer to GPU"
time=2025-08-20T11:03:44.923Z level=INFO source=ggml.go:497 msg="offloaded 37/37 layers to GPU"
time=2025-08-20T11:03:44.924Z level=INFO source=backend.go:310 msg="model weights" device=CUDA0 size="31.0 GiB"
time=2025-08-20T11:03:44.924Z level=INFO source=backend.go:310 msg="model weights" device=CUDA1 size="28.8 GiB"
time=2025-08-20T11:03:44.924Z level=INFO source=backend.go:315 msg="model weights" device=CPU size="1.1 GiB"
time=2025-08-20T11:03:44.925Z level=INFO source=backend.go:321 msg="kv cache" device=CUDA0 size="234.0 MiB"
time=2025-08-20T11:03:44.925Z level=INFO source=backend.go:321 msg="kv cache" device=CUDA1 size="216.0 MiB"
time=2025-08-20T11:03:44.925Z level=INFO source=backend.go:332 msg="compute graph" device=CUDA0 size="1.1 GiB"
time=2025-08-20T11:03:44.926Z level=INFO source=backend.go:332 msg="compute graph" device=CUDA1 size="1.1 GiB"
time=2025-08-20T11:03:44.926Z level=INFO source=backend.go:337 msg="compute graph" device=CPU size="5.6 MiB"
time=2025-08-20T11:03:44.926Z level=INFO source=backend.go:342 msg="total memory" size="63.4 GiB"
time=2025-08-20T11:03:44.926Z level=INFO source=sched.go:473 msg="loaded runners" count=1
time=2025-08-20T11:03:44.927Z level=INFO source=server.go:1234 msg="waiting for llama runner to start responding"
time=2025-08-20T11:03:44.928Z level=INFO source=server.go:1268 msg="waiting for server to become available" status="llm server loading model"
time=2025-08-20T11:04:16.131Z level=INFO source=server.go:1272 msg="llama runner started in 32.47 seconds"
[GIN] 2025/08/20 - 11:04:58 | 200 |         1m16s |       127.0.0.1 | POST     "/api/generate"
time=2025-08-20T11:18:15.942Z level=INFO source=server.go:383 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /root/.ollama/models/blobs/sha256-90a618fe6ff21b09ca968df959104eb650658b0bef0faef785c18c2795d993e3 --port 41209"
time=2025-08-20T11:18:15.967Z level=INFO source=runner.go:1006 msg="starting ollama engine"
time=2025-08-20T11:18:15.968Z level=INFO source=runner.go:1043 msg="Server listening on 127.0.0.1:41209"
time=2025-08-20T11:18:16.422Z level=INFO source=server.go:488 msg="system memory" total="503.5 GiB" free="417.1 GiB" free_swap="0 B"
time=2025-08-20T11:18:16.424Z level=INFO source=memory.go:36 msg="new model will fit in available VRAM across minimum required GPUs, loading" model=/root/.ollama/models/blobs/sha256-90a618fe6ff21b09ca968df959104eb650658b0bef0faef785c18c2795d993e3 library=cuda parallel=1 required="67.3 GiB" gpus=2
time=2025-08-20T11:18:16.424Z level=INFO source=server.go:531 msg=offload library=cuda layers.requested=-1 layers.model=37 layers.offload=37 layers.split="[19 18]" memory.available="[44.1 GiB 44.1 GiB]" memory.gpu_overhead="0 B" memory.required.full="67.3 GiB" memory.required.partial="67.3 GiB" memory.required.kv="450.0 MiB" memory.required.allocations="[34.1 GiB 33.2 GiB]" memory.weights.total="59.7 GiB" memory.weights.repeating="58.6 GiB" memory.weights.nonrepeating="1.1 GiB" memory.graph.full="1.5 GiB" memory.graph.partial="1.5 GiB"
time=2025-08-20T11:18:16.427Z level=INFO source=runner.go:925 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:false KvSize:8192 KvCacheType: NumThreads:48 GPULayers:37[ID:GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef Layers:19(0..18) ID:GPU-5099149b-3124-0eff-3dd9-68d769ce801f Layers:18(19..36)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-08-20T11:18:16.559Z level=INFO source=ggml.go:130 msg="" architecture=gptoss file_type=MXFP4 name="" description="" num_tensors=471 num_key_values=30
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 2 CUDA devices:
  Device 0: NVIDIA A40, compute capability 8.6, VMM: yes, ID: GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef
  Device 1: NVIDIA A40, compute capability 8.6, VMM: yes, ID: GPU-5099149b-3124-0eff-3dd9-68d769ce801f
load_backend: loaded CUDA backend from /usr/local/lib/ollama/libggml-cuda.so
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
time=2025-08-20T11:18:16.860Z level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 CUDA.1.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.1.USE_GRAPHS=1 CUDA.1.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-08-20T11:18:17.049Z level=INFO source=ggml.go:486 msg="offloading 36 repeating layers to GPU"
time=2025-08-20T11:18:17.049Z level=INFO source=ggml.go:492 msg="offloading output layer to GPU"
time=2025-08-20T11:18:17.049Z level=INFO source=ggml.go:497 msg="offloaded 37/37 layers to GPU"
time=2025-08-20T11:18:17.051Z level=INFO source=backend.go:310 msg="model weights" device=CUDA0 size="31.0 GiB"
time=2025-08-20T11:18:17.051Z level=INFO source=backend.go:310 msg="model weights" device=CUDA1 size="28.8 GiB"
time=2025-08-20T11:18:17.052Z level=INFO source=backend.go:315 msg="model weights" device=CPU size="1.1 GiB"
time=2025-08-20T11:18:17.052Z level=INFO source=backend.go:321 msg="kv cache" device=CUDA0 size="234.0 MiB"
time=2025-08-20T11:18:17.052Z level=INFO source=backend.go:321 msg="kv cache" device=CUDA1 size="216.0 MiB"
time=2025-08-20T11:18:17.053Z level=INFO source=backend.go:332 msg="compute graph" device=CUDA0 size="1.1 GiB"
time=2025-08-20T11:18:17.053Z level=INFO source=backend.go:332 msg="compute graph" device=CUDA1 size="1.1 GiB"
time=2025-08-20T11:18:17.054Z level=INFO source=backend.go:337 msg="compute graph" device=CPU size="5.6 MiB"
time=2025-08-20T11:18:17.054Z level=INFO source=backend.go:342 msg="total memory" size="63.4 GiB"
time=2025-08-20T11:18:17.055Z level=INFO source=sched.go:473 msg="loaded runners" count=1
time=2025-08-20T11:18:17.055Z level=INFO source=server.go:1234 msg="waiting for llama runner to start responding"
time=2025-08-20T11:18:17.056Z level=INFO source=server.go:1268 msg="waiting for server to become available" status="llm server loading model"
time=2025-08-20T11:18:55.602Z level=INFO source=server.go:1272 msg="llama runner started in 39.66 seconds"
[GIN] 2025/08/20 - 11:19:32 | 200 |         1m18s |       127.0.0.1 | POST     "/api/generate"
time=2025-08-20T11:27:48.428Z level=INFO source=server.go:383 msg="starting runner" cmd="/usr/local/bin/ollama runner --ollama-engine --model /root/.ollama/models/blobs/sha256-90a618fe6ff21b09ca968df959104eb650658b0bef0faef785c18c2795d993e3 --port 42805"
time=2025-08-20T11:27:48.454Z level=INFO source=runner.go:1006 msg="starting ollama engine"
time=2025-08-20T11:27:48.454Z level=INFO source=runner.go:1043 msg="Server listening on 127.0.0.1:42805"
time=2025-08-20T11:27:49.090Z level=INFO source=server.go:488 msg="system memory" total="503.5 GiB" free="417.1 GiB" free_swap="0 B"
time=2025-08-20T11:27:49.093Z level=INFO source=memory.go:36 msg="new model will fit in available VRAM across minimum required GPUs, loading" model=/root/.ollama/models/blobs/sha256-90a618fe6ff21b09ca968df959104eb650658b0bef0faef785c18c2795d993e3 library=cuda parallel=1 required="67.3 GiB" gpus=2
time=2025-08-20T11:27:49.094Z level=INFO source=server.go:531 msg=offload library=cuda layers.requested=-1 layers.model=37 layers.offload=37 layers.split="[19 18]" memory.available="[44.1 GiB 44.1 GiB]" memory.gpu_overhead="0 B" memory.required.full="67.3 GiB" memory.required.partial="67.3 GiB" memory.required.kv="450.0 MiB" memory.required.allocations="[34.1 GiB 33.2 GiB]" memory.weights.total="59.7 GiB" memory.weights.repeating="58.6 GiB" memory.weights.nonrepeating="1.1 GiB" memory.graph.full="1.5 GiB" memory.graph.partial="1.5 GiB"
time=2025-08-20T11:27:49.096Z level=INFO source=runner.go:925 msg=load request="{Operation:commit LoraPath:[] Parallel:1 BatchSize:512 FlashAttention:false KvSize:8192 KvCacheType: NumThreads:48 GPULayers:37[ID:GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef Layers:19(0..18) ID:GPU-5099149b-3124-0eff-3dd9-68d769ce801f Layers:18(19..36)] MultiUserCache:false ProjectorPath: MainGPU:0 UseMmap:false}"
time=2025-08-20T11:27:49.226Z level=INFO source=ggml.go:130 msg="" architecture=gptoss file_type=MXFP4 name="" description="" num_tensors=471 num_key_values=30
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 2 CUDA devices:
  Device 0: NVIDIA A40, compute capability 8.6, VMM: yes, ID: GPU-77b16ff9-727a-e55f-1dad-8d846ab2d1ef
  Device 1: NVIDIA A40, compute capability 8.6, VMM: yes, ID: GPU-5099149b-3124-0eff-3dd9-68d769ce801f
load_backend: loaded CUDA backend from /usr/local/lib/ollama/libggml-cuda.so
load_backend: loaded CPU backend from /usr/local/lib/ollama/libggml-cpu-icelake.so
time=2025-08-20T11:27:49.518Z level=INFO source=ggml.go:104 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.AVX512=1 CPU.0.AVX512_VBMI=1 CPU.0.AVX512_VNNI=1 CPU.0.LLAMAFILE=1 CPU.1.LLAMAFILE=1 CUDA.0.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.0.USE_GRAPHS=1 CUDA.0.PEER_MAX_BATCH_SIZE=128 CUDA.1.ARCHS=500,600,610,700,750,800,860,870,890,900,1200 CUDA.1.USE_GRAPHS=1 CUDA.1.PEER_MAX_BATCH_SIZE=128 compiler=cgo(gcc)
time=2025-08-20T11:27:49.705Z level=INFO source=ggml.go:486 msg="offloading 36 repeating layers to GPU"
time=2025-08-20T11:27:49.705Z level=INFO source=ggml.go:492 msg="offloading output layer to GPU"
time=2025-08-20T11:27:49.705Z level=INFO source=ggml.go:497 msg="offloaded 37/37 layers to GPU"
time=2025-08-20T11:27:49.706Z level=INFO source=backend.go:310 msg="model weights" device=CUDA0 size="31.0 GiB"
time=2025-08-20T11:27:49.707Z level=INFO source=backend.go:310 msg="model weights" device=CUDA1 size="28.8 GiB"
time=2025-08-20T11:27:49.708Z level=INFO source=backend.go:315 msg="model weights" device=CPU size="1.1 GiB"
time=2025-08-20T11:27:49.708Z level=INFO source=backend.go:321 msg="kv cache" device=CUDA0 size="234.0 MiB"
time=2025-08-20T11:27:49.708Z level=INFO source=backend.go:321 msg="kv cache" device=CUDA1 size="216.0 MiB"
time=2025-08-20T11:27:49.709Z level=INFO source=backend.go:332 msg="compute graph" device=CUDA0 size="1.1 GiB"
time=2025-08-20T11:27:49.709Z level=INFO source=backend.go:332 msg="compute graph" device=CUDA1 size="1.1 GiB"
time=2025-08-20T11:27:49.710Z level=INFO source=backend.go:337 msg="compute graph" device=CPU size="5.6 MiB"
time=2025-08-20T11:27:49.710Z level=INFO source=backend.go:342 msg="total memory" size="63.4 GiB"
time=2025-08-20T11:27:49.711Z level=INFO source=sched.go:473 msg="loaded runners" count=1
time=2025-08-20T11:27:49.711Z level=INFO source=server.go:1234 msg="waiting for llama runner to start responding"
time=2025-08-20T11:27:49.713Z level=INFO source=server.go:1268 msg="waiting for server to become available" status="llm server loading model"
time=2025-08-20T11:28:29.343Z level=INFO source=server.go:1272 msg="llama runner started in 40.91 seconds"
[GIN] 2025/08/20 - 11:29:12 | 200 |         1m25s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:33:50 | 200 | 36.588768473s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:34:22 | 200 |  32.38543487s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:35:04 | 200 | 41.736018275s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:35:57 | 200 | 52.729049832s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:36:43 | 200 | 46.270855512s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:37:58 | 200 |         1m14s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:38:45 | 200 | 46.858950373s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:39:28 | 200 | 43.130720715s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:40:04 | 200 | 35.399445521s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:40:45 | 200 | 41.757285423s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:41:18 | 200 |  32.94177852s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:41:57 | 200 | 38.011625064s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:42:49 | 200 | 52.746136752s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:43:32 | 200 | 41.993684581s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:44:15 | 200 | 42.862193872s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:44:55 | 200 | 40.179438906s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:45:28 | 200 | 32.527721936s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:46:13 | 200 | 45.348637993s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:47:14 | 200 |          1m0s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:47:53 | 200 | 38.939971738s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:48:33 | 200 | 39.840153608s |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:48:52 | 200 |       59.34µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/20 - 11:48:52 | 200 |    1.074704ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/08/20 - 11:51:02 | 200 |      63.353µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/20 - 11:51:02 | 200 |    3.156716ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/08/20 - 11:51:08 | 200 |  5.711571356s |       127.0.0.1 | DELETE   "/api/delete"
[GIN] 2025/08/20 - 11:51:19 | 200 |      61.009µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/20 - 11:51:19 | 404 |     505.686µs |       127.0.0.1 | POST     "/api/show"
time=2025-08-20T11:51:20.161Z level=INFO source=download.go:177 msg="downloading 07ca3450446e in 55 1 GB part(s)"
